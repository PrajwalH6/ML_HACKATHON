{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cdd3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# HMM Training and Analysis\\n\",\n",
    "    \"This notebook trains the Hidden Markov Model emissions for Hangman letter prediction.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import pickle\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.utils.data_loader import CorpusLoader\\n\",\n",
    "    \"from src.hmm.emissions import EmissionBuilder\\n\",\n",
    "    \"from src.hmm.oracle import HMMOracle\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Explore Corpus\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load corpus\\n\",\n",
    "    \"loader = CorpusLoader('../data/raw/corpus.txt')\\n\",\n",
    "    \"words_by_length, letter_freq = loader.load_and_preprocess()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Total unique words: {sum(len(v) for v in words_by_length.values())}\\\")\\n\",\n",
    "    \"print(f\\\"Word lengths: {sorted(words_by_length.keys())}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot word length distribution\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"lengths = sorted(words_by_length.keys())\\n\",\n",
    "    \"counts = [len(words_by_length[l]) for l in lengths]\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.bar(lengths, counts, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"plt.xlabel('Word Length')\\n\",\n",
    "    \"plt.ylabel('Number of Words')\\n\",\n",
    "    \"plt.title('Distribution of Word Lengths in Corpus')\\n\",\n",
    "    \"plt.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot letter frequency\\n\",\n",
    "    \"plt.figure(figsize=(12, 5))\\n\",\n",
    "    \"letters = sorted(letter_freq.keys())\\n\",\n",
    "    \"freqs = [letter_freq[l] for l in letters]\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.bar(letters, freqs, edgecolor='black', alpha=0.7, color='steelblue')\\n\",\n",
    "    \"plt.xlabel('Letter')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"plt.title('Overall Letter Frequency in Corpus')\\n\",\n",
    "    \"plt.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Top 10 letters\\n\",\n",
    "    \"sorted_letters = sorted(letter_freq.items(), key=lambda x: x[1], reverse=True)\\n\",\n",
    "    \"print(\\\"\\\\nTop 10 most frequent letters:\\\")\\n\",\n",
    "    \"for letter, freq in sorted_letters[:10]:\\n\",\n",
    "    \"    print(f\\\"{letter}: {freq}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Build HMM Emissions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Build emissions with smoothing\\n\",\n",
    "    \"builder = EmissionBuilder(smoothing_alpha=1.0)\\n\",\n",
    "    \"emissions = builder.build_from_corpus(words_by_length)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nEmissions trained for {len(emissions)} different word lengths\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Analyze Emissions for Sample Length\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze emissions for 5-letter words\\n\",\n",
    "    \"sample_length = 5\\n\",\n",
    "    \"if sample_length in emissions:\\n\",\n",
    "    \"    position_emissions = emissions[sample_length]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create heatmap\\n\",\n",
    "    \"    letters = list('abcdefghijklmnopqrstuvwxyz')\\n\",\n",
    "    \"    emission_matrix = np.zeros((sample_length, 26))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for pos in range(sample_length):\\n\",\n",
    "    \"        for i, letter in enumerate(letters):\\n\",\n",
    "    \"            emission_matrix[pos, i] = position_emissions[pos][letter]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(14, 6))\\n\",\n",
    "    \"    sns.heatmap(emission_matrix, \\n\",\n",
    "    \"                xticklabels=letters,\\n\",\n",
    "    \"                yticklabels=[f'Pos {i}' for i in range(sample_length)],\\n\",\n",
    "    \"                cmap='YlOrRd',\\n\",\n",
    "    \"                cbar_kws={'label': 'Probability'})\\n\",\n",
    "    \"    plt.title(f'Letter Emission Probabilities for {sample_length}-Letter Words')\\n\",\n",
    "    \"    plt.xlabel('Letter')\\n\",\n",
    "    \"    plt.ylabel('Position')\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Show top letters per position\\n\",\n",
    "    \"    print(f\\\"\\\\nTop 5 letters per position for {sample_length}-letter words:\\\")\\n\",\n",
    "    \"    for pos in range(sample_length):\\n\",\n",
    "    \"        top_letters = sorted(position_emissions[pos].items(), \\n\",\n",
    "    \"                           key=lambda x: x[1], reverse=True)[:5]\\n\",\n",
    "    \"        print(f\\\"Position {pos}: {', '.join([f'{l}({p:.3f})' for l, p in top_letters])}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Test HMM Oracle Predictions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create oracle\\n\",\n",
    "    \"oracle = HMMOracle(emissions, words_by_length)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test with sample mask\\n\",\n",
    "    \"test_mask = \\\"_pp__\\\"\\n\",\n",
    "    \"guessed = set(['a', 'p'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"probs = oracle.get_letter_probs(test_mask, guessed)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sort and display top predictions\\n\",\n",
    "    \"sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)[:10]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nTop 10 predictions for mask '{test_mask}' (guessed: {guessed}):\\\")\\n\",\n",
    "    \"for letter, prob in sorted_probs:\\n\",\n",
    "    \"    print(f\\\"{letter}: {prob:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize\\n\",\n",
    "    \"letters = [l for l, _ in sorted_probs]\\n\",\n",
    "    \"probs_vals = [p for _, p in sorted_probs]\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 5))\\n\",\n",
    "    \"plt.bar(letters, probs_vals, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"plt.xlabel('Letter')\\n\",\n",
    "    \"plt.ylabel('Probability')\\n\",\n",
    "    \"plt.title(f'HMM Predictions for Mask: {test_mask}')\\n\",\n",
    "    \"plt.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Save Processed Data and Emissions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save preprocessed data\\n\",\n",
    "    \"loader.save_processed('../data/processed')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save emissions\\n\",\n",
    "    \"Path('../models/hmm').mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"builder.save('../models/hmm/emissions.pkl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nData and emissions saved successfully!\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.12.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
